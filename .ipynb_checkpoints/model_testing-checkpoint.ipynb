{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T09:35:10.435742Z",
     "start_time": "2025-01-04T09:35:07.560498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras._tf_keras.keras as keras\n",
    "from keras._tf_keras.keras.models import Model\n",
    "from keras._tf_keras.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, GlobalAveragePooling3D\n",
    "from keras._tf_keras.keras.layers import Dropout, concatenate, multiply, Dense, GroupNormalization\n",
    "from keras._tf_keras.keras.layers import LeakyReLU\n",
    "from keras._tf_keras.keras.optimizers import Adam\n",
    "from keras._tf_keras.keras.utils import to_categorical"
   ],
   "id": "a898e2ae3595cead",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 15:05:08.021700: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-04 15:05:08.138956: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735983308.183406   73549 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735983308.197029   73549 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-04 15:05:08.301822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-04T09:35:10.457123Z",
     "start_time": "2025-01-04T09:35:10.444906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class InstanceNormalization(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(InstanceNormalization, self).__init__(**kwargs)\n",
    "        self.norm = GroupNormalization(groups=-1)\n",
    "    def call(self, x):\n",
    "        return self.norm(x)\n",
    "\n",
    "# Squeeze-and-Excitation layer\n",
    "class SE_Layer(keras.layers.Layer):\n",
    "    def __init__(self, ch, ratio = 16, **kwargs):\n",
    "        super(SE_Layer, self).__init__(**kwargs)\n",
    "        self.gl = GlobalAveragePooling3D()\n",
    "        self.fc1 = Dense(ch//ratio, activation='relu')\n",
    "        self.fc2 = Dense(ch, activation='sigmoid')\n",
    "    def call(self, input_block):\n",
    "        x = self.gl(input_block)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return multiply([input_block, x])\n",
    "\n",
    "# Model\n",
    "def My_LATUP(input_shape: tuple, loss)->keras.Model:\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder Block 1 (Parallel Convolutions Block) (E1)\n",
    "    e1_pc_embed = Conv3D(32, (3, 3, 3), strides=(1, 1, 1), activation=LeakyReLU(negative_slope=0.1), padding='same', name='E1_PC_Embedded_Layer')(inputs)\n",
    "    e1_pc_conv1 = Conv3D(32, (1, 1, 1), strides=(1, 1, 1), activation=LeakyReLU(negative_slope=0.1), padding='same', name='E1_PC_Conv1_Layer')(e1_pc_embed)\n",
    "    e1_pc_conv2 = Conv3D(32, (3, 3, 3), strides=(1, 1, 1), activation=LeakyReLU(negative_slope=0.1), padding='same', name='E1_PC_Conv2_Layer')(e1_pc_embed)\n",
    "    e1_pc_conv3 = Conv3D(32, (5, 5, 5), strides=(1, 1, 1), activation=LeakyReLU(negative_slope=0.1), padding='same', name='E1_PC_Conv3_Layer')(e1_pc_embed)\n",
    "\n",
    "    e1_pc_maxpool1 = MaxPooling3D(pool_size=(2, 3, 3), name='E1_maxpool1_Layer')(e1_pc_conv1)\n",
    "    e1_pc_maxpool2 = MaxPooling3D(pool_size=(2, 3, 3), name='E1_maxpool2_Layer')(e1_pc_conv2)\n",
    "    e1_pc_maxpool3 = MaxPooling3D(pool_size=(2, 3, 3), name='E1_maxpool3_Layer')(e1_pc_conv3)\n",
    "\n",
    "    e1_pc_concat = concatenate([e1_pc_maxpool1, e1_pc_maxpool2, e1_pc_maxpool3], name='E1_concat_Layer')\n",
    "\n",
    "    #Encoder Block 2 (E2)\n",
    "    e2_se1 = SE_Layer(96, ratio=8, name='E2_SE1_Layer')(e1_pc_concat)\n",
    "    e2_conv1 = Conv3D(64, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='E2_Conv1_Layer')(e2_se1)\n",
    "    e2_instance = InstanceNormalization(name='E2_instance_Layer')(e2_conv1)\n",
    "    e2_conv2 = Conv3D(64, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='E2_Conv2_Layer')(e2_instance)\n",
    "    e2_dropout = Dropout(0.2, name='E2_Drop')(e2_conv2)\n",
    "    e2_maxpool1 = MaxPooling3D(pool_size=(2, 3, 3), name='E2_maxpool1_Layer')(e2_dropout)\n",
    "\n",
    "    #Encoder Block 3 (E3)\n",
    "    e3_se1 = SE_Layer(64, ratio=8, name='E3_SE1_Layer')(e2_maxpool1)\n",
    "    e3_conv1 = Conv3D(128, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='E3_Conv1_Layer')(e3_se1)\n",
    "    e3_instance = InstanceNormalization(name='E3_instance_Layer')(e3_conv1)\n",
    "    e3_conv2 = Conv3D(128, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='E3_Conv2_Layer')(e3_instance)\n",
    "    e3_dropout = Dropout(0.2, name='E3_drop')(e3_conv2)\n",
    "    e3_maxpool1 = MaxPooling3D(pool_size=(2, 2, 2), name='E3_maxpool1_Layer')(e3_dropout)\n",
    "\n",
    "    bn_se1 = SE_Layer(128, ratio=8, name='BN_SE1_Layer')(e3_maxpool1)\n",
    "\n",
    "    #Decoder Block 3 (D3)\n",
    "    d3_up = UpSampling3D(size=(2, 2, 2), name='D3_up')(bn_se1)\n",
    "    d3_conv1 = Conv3D(128, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='D3_Conv1_Layer')(d3_up)\n",
    "    d3_instance = InstanceNormalization(name='D3_instance_Layer')(d3_conv1)\n",
    "    d3_concat = concatenate([d3_instance, e3_dropout], name='D3_concat_Layer')\n",
    "    d3_conv2 = Conv3D(128, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='D3_Conv2_Layer')(d3_concat)\n",
    "    d3_se1 = SE_Layer(128, ratio=8, name='D3_SE1_Layer')(d3_conv2)\n",
    "    d3_dropout = Dropout(0.2, name='D3_drop')(d3_se1)\n",
    "    d3_conv3 = Conv3D(128, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='D3_Conv3_Layer')(d3_dropout)\n",
    "\n",
    "    #Decoder Block 2(D2)\n",
    "    d2_up = UpSampling3D(size=(2, 3, 3), name='D2_up')(d3_conv3)\n",
    "    d2_conv1 = Conv3D(64, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='D2_Conv1_Layer')(d2_up)\n",
    "    d2_instance = InstanceNormalization(name='D2_instance_Layer')(d2_conv1)\n",
    "    d2_concat = concatenate([d2_instance, e2_dropout], name='D2_concat_Layer')\n",
    "    d2_conv2 = Conv3D(64, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='D2_Conv2_Layer')(d2_concat)\n",
    "    d2_se1 = SE_Layer(64, ratio=8, name='D2_SE1_Layer')(d2_conv2)\n",
    "    d2_dropout = Dropout(0.2, name='D2_drop')(d2_se1)\n",
    "    d2_conv3 = Conv3D(64, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='D2_Conv3_Layer')(d2_dropout)\n",
    "\n",
    "    #Decoder Block 1(D1)\n",
    "    d1_up = UpSampling3D(size=(2, 3, 3), name='D1_up')(d2_conv3)\n",
    "    d1_conv1 = Conv3D(32, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='D1_Conv1_Layer')(d1_up)\n",
    "    d1_instance = InstanceNormalization(name='D1_instance_Layer')(d1_conv1)\n",
    "    d1_concat = concatenate([d1_instance, e1_pc_embed], name='D1_concat_Layer')\n",
    "    d1_conv2 = Conv3D(32, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='D1_Conv2_Layer')(d1_concat)\n",
    "    d1_se1 = SE_Layer(32, ratio=8, name='D1_SE1_Layer')(d1_conv2)\n",
    "    d1_dropout = Dropout(0.2, name='D1_drop')(d1_se1)\n",
    "    d1_conv3 = Conv3D(32, (3, 3, 3), activation=LeakyReLU(negative_slope=0.1), padding='same', name='D1_Conv3_Layer')(d1_dropout)\n",
    "\n",
    "    #Probablity Filter\n",
    "    prob = Conv3D(1, (1, 1, 1), activation='softmax', name='prob')(d1_conv3)\n",
    "\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=e1_pc_embed, name='MY_LATUP')\n",
    "    model.compile(loss=loss, optimizer=Adam(beta_1=0.9, beta_2=0.999, learning_rate=0.0001), metrics=['accuracy'])\n",
    "    return model"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T09:35:14.024566Z",
     "start_time": "2025-01-04T09:35:10.977038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from deepfindET.utils import copick_tools\n",
    "import copick\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "copick_config_path = \"working/copick.json\"\n",
    "copick_root = copick.from_file(copick_config_path)\n",
    "\n",
    "runs = os.listdir('Extracted_Data/train/static/ExperimentRuns')\n",
    "voxel_size = 10\n",
    "tomogram_algo = 'denoised'\n",
    "\n",
    "out_name = 'remotetargets'\n",
    "out_user_id = 'deepfindET'\n",
    "out_session_id = '0'\n",
    "\n",
    "tomograms = np.array([copick_tools.get_copick_tomogram(copick_root,\n",
    "                                                       voxelSize=voxel_size,\n",
    "                                                       tomoAlgorithm=tomogram_algo,\n",
    "                                                       tomoID=i) for i in runs])\n",
    "\n",
    "masks = np.array([copick_tools.get_copick_segmentation(copick_root.get_run(i),\n",
    "                                                       segmentationName=out_name,\n",
    "                                                       userID=out_user_id,\n",
    "                                                       sessionID=out_session_id) for i in runs])\n"
   ],
   "id": "51d7f3a65c23ca66",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T09:35:15.382125Z",
     "start_time": "2025-01-04T09:35:14.657301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "tomograms_patches = []\n",
    "for i in tomograms:\n",
    "    temp = patchify(i, patch_size=(128,128,128), step=128)\n",
    "    temp = np.reshape(temp,(-1, temp.shape[3], temp.shape[4], temp.shape[5]))\n",
    "    tomograms_patches.append(temp)\n",
    "\n",
    "mask_patches = []\n",
    "for i in masks:\n",
    "    temp = patchify(i, patch_size=(128,128,128), step=128)\n",
    "    temp = np.reshape(temp,(-1, temp.shape[3], temp.shape[4], temp.shape[5]))\n",
    "    mask_patches.append(temp)\n",
    "\n",
    "\n",
    "tomograms_patches = np.array(tomograms_patches)\n",
    "print(tomograms_patches.shape)\n",
    "\n",
    "mask_patches = np.array(mask_patches)\n",
    "print(mask_patches.shape)\n"
   ],
   "id": "3b46e32bee236a4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 16, 128, 128, 128)\n",
      "(7, 16, 128, 128, 128)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T09:35:16.099878Z",
     "start_time": "2025-01-04T09:35:16.093626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tomograms = np.reshape(tomograms_patches,(-1,tomograms_patches.shape[2],tomograms_patches.shape[3],tomograms_patches.shape[4]))\n",
    "masks = np.reshape(mask_patches,(-1,mask_patches.shape[2],mask_patches.shape[3],mask_patches.shape[4]))\n",
    "print(tomograms.shape)\n",
    "print(masks.shape)"
   ],
   "id": "a70aa7f48a5f3c4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 128, 128, 128)\n",
      "(112, 128, 128, 128)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T09:35:18.116640Z",
     "start_time": "2025-01-04T09:35:17.287682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_tomograms = np.stack((tomograms,)*3, axis=-1)\n",
    "train_masks = np.expand_dims(masks, axis=4)\n",
    "print(train_tomograms.shape)\n",
    "print(train_masks.shape)"
   ],
   "id": "7d0a97c987ee2cc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 128, 128, 128, 3)\n",
      "(112, 128, 128, 128, 1)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T10:12:48.505597500Z",
     "start_time": "2025-01-04T09:35:18.871397Z"
    }
   },
   "cell_type": "code",
   "source": "train_masks = to_categorical(train_masks, num_classes=8)",
   "id": "8d89ebd87ce261b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(train_tomograms, train_masks, test_size=0.2, random_state=42)",
   "id": "793c265997ee444f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "id": "6bb43260797bfdb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = My_LATUP(input_shape=(184, 630, 630, 3), loss = keras.losses.dice)\n",
    "model.summary()"
   ],
   "id": "72a5bd7a9167c27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# model.fit(X_train, y_train, batch_size=1, epochs=3, validation_data=(X_test, y_test))",
   "id": "53a930326d004467",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.predict(X_test)",
   "id": "558a9dc32701e721",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "752d008070c36d8c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
